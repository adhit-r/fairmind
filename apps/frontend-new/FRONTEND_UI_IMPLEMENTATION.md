# ğŸ¯ FairMind Frontend UI - MLOps Integration

## âœ… What We Built

This implementation adds comprehensive **dataset management** and **bias test history** features to the FairMind frontend, creating a complete MLOps workflow for bias detection.

---

## ğŸ“¦ New Features

### 1. **Test History Page** (`/dashboard/tests`)
- **View all bias detection tests** in a searchable, filterable table
- **Filter by test type**: ML Bias vs LLM Bias
- **Search** by model ID, test ID, or summary
- **Quick statistics**: Total tests, passed, warnings, critical
- **Risk level badges**: Visual indicators for low/medium/high/critical
- **Direct navigation** to detailed test results

### 2. **Test Detail Page** (`/dashboard/tests/[testId]`)
- **Comprehensive test results** with full metrics breakdown
- **Visual representations**: Progress bars for each metric
- **Pass/Fail distribution** with percentage breakdowns
- **Group scores** for each protected attribute
- **Detailed interpretations** for each fairness metric
- **Actionable recommendations** for bias mitigation
- **Export functionality**: Download results as JSON

### 3. **Enhanced Dataset Management** (`/dashboard/datasets/[datasetId]`)
- **Dataset detail view** with complete metadata
- **Schema visualization**: All columns with data types
- **Data preview**: First N rows of the dataset
- **File statistics**: Row count, column count, file size
- **Quick actions**: Run bias test directly from dataset
- **Delete functionality**: Remove datasets with confirmation

### 4. **Updated Datasets Page** (`/dashboard/datasets`)
- **Clickable rows** for easy navigation
- **View button** to access dataset details
- **Upload dialog** for new datasets
- **Status indicators** for active datasets

---

## ğŸ”§ Technical Implementation

### New API Endpoints (`/lib/api/endpoints.ts`)
```typescript
biasV2: {
  uploadDataset: '/api/v1/bias-v2/upload-dataset',
  detect: '/api/v1/bias-v2/detect',
  detectLLM: '/api/v1/bias-v2/detect-llm',
  getTest: (testId) => `/api/v1/bias-v2/test/${testId}`,
  datasets: '/api/v1/bias-v2/datasets',
  getDataset: (datasetId) => `/api/v1/bias-v2/datasets/${datasetId}`,
  deleteDataset: (datasetId) => `/api/v1/bias-v2/datasets/${datasetId}`,
  history: '/api/v1/bias-v2/history',
  statistics: '/api/v1/bias-v2/statistics',
}
```

### Custom React Hooks (`/lib/api/hooks/useTestHistory.ts`)
- `useTestHistory()` - Fetch and filter test history
- `useTestStatistics()` - Get aggregated statistics
- `useTestDetail()` - Fetch detailed test results

### Key Components
- **Test History Table**: Sortable, filterable, paginated
- **Test Detail Cards**: Modular metric displays
- **Dataset Schema Grid**: Visual column type indicators
- **Progress Visualizations**: Custom progress bars for metrics

---

## ğŸ¨ UI/UX Features

### Design System
- **Brutal Design**: Consistent 2px black borders, shadow effects
- **Color-coded Risk Levels**:
  - ğŸŸ¢ Low: Green (#22c55e)
  - ğŸŸ¡ Medium: Yellow (#eab308)
  - ğŸŸ  High: Orange (#f97316)
  - ğŸ”´ Critical: Red (#ef4444)

### Interactive Elements
- **Hover effects** on table rows
- **Loading skeletons** for better UX
- **Toast notifications** for actions
- **Confirmation dialogs** for destructive actions

---

## ğŸ“Š Data Flow

```
User Action â†’ Frontend Hook â†’ API Client â†’ Backend (bias-v2) â†’ Supabase
                                                                    â†“
                                                            bias_test_results
                                                            datasets
```

### Test History Flow
1. User navigates to `/dashboard/tests`
2. `useTestHistory()` hook fetches from `/api/v1/bias-v2/history`
3. Backend queries Supabase `bias_test_results` table
4. Results displayed in table with filters
5. Click test â†’ Navigate to `/dashboard/tests/[testId]`
6. `useTestDetail()` fetches full results
7. Display metrics, visualizations, recommendations

### Dataset Management Flow
1. User uploads dataset via `/dashboard/datasets`
2. File sent to `/api/v1/bias-v2/upload-dataset`
3. Backend stores in Supabase Storage + metadata in DB
4. Dataset appears in list with ID
5. Click dataset â†’ Navigate to `/dashboard/datasets/[datasetId]`
6. Display schema, preview, metadata
7. "Run Bias Test" button â†’ Pre-fill bias detection form

---

## ğŸš€ Usage Examples

### Running a Bias Test
```typescript
// 1. Upload dataset
POST /api/v1/bias-v2/upload-dataset
Body: FormData with CSV file

// 2. Run bias detection
POST /api/v1/bias-v2/detect
Body: {
  model_id: "credit-model-v1",
  dataset_id: "ds_20251123_abc123",
  protected_attribute: "gender",
  prediction_column: "approved",
  fairness_threshold: 0.8
}

// 3. View results
GET /api/v1/bias-v2/test/ml-test-20251123010000
```

### Viewing Test History
```typescript
// Get all tests
GET /api/v1/bias-v2/history?limit=50&offset=0

// Filter by model
GET /api/v1/bias-v2/history?model_id=credit-model-v1

// Filter by type
GET /api/v1/bias-v2/history?test_type=ml_bias
```

### Getting Statistics
```typescript
// Overall statistics
GET /api/v1/bias-v2/statistics

// Model-specific statistics
GET /api/v1/bias-v2/statistics?model_id=credit-model-v1

// Returns:
{
  total_tests: 42,
  ml_tests: 30,
  llm_tests: 12,
  risk_distribution: {
    low: 20,
    medium: 15,
    high: 5,
    critical: 2
  },
  pass_rate: 0.71
}
```

---

## ğŸ”— Integration with Backend

### Backend Requirements
The backend (`/apps/backend`) already has:
- âœ… Supabase integration (`services/bias_test_results.py`)
- âœ… Dataset storage (`services/dataset_storage.py`)
- âœ… Bias detection v2 API (`api/routes/bias_detection_v2.py`)
- âœ… Database schema (`supabase/bias_test_results_setup.sql`)

### Supabase Schema
```sql
-- Test Results Table
bias_test_results (
  id TEXT PRIMARY KEY,
  user_id TEXT NOT NULL,
  model_id TEXT NOT NULL,
  dataset_id TEXT,
  test_type TEXT CHECK (test_type IN ('ml_bias', 'llm_bias')),
  timestamp TIMESTAMP WITH TIME ZONE,
  overall_risk TEXT CHECK (overall_risk IN ('low', 'medium', 'high', 'critical')),
  metrics_passed INTEGER,
  metrics_failed INTEGER,
  results JSONB,
  summary TEXT,
  recommendations TEXT[],
  metadata JSONB
)
```

---

## ğŸ¯ Next Steps: MLOps Integrations

Now that the UI foundation is complete, you can add:

### Option 1: Weights & Biases (W&B) Integration
- Log test results to W&B
- Track metrics over time
- Compare model versions
- Team collaboration

### Option 2: MLflow Integration
- Open-source experiment tracking
- Self-hosted option
- Model registry
- Artifact storage

### Option 3: DVC Integration
- Data version control
- Dataset lineage tracking
- Reproducible pipelines

---

## ğŸ“ Files Created/Modified

### New Files
- `/apps/frontend-new/src/lib/api/hooks/useTestHistory.ts`
- `/apps/frontend-new/src/app/(dashboard)/tests/page.tsx`
- `/apps/frontend-new/src/app/(dashboard)/tests/[testId]/page.tsx`
- `/apps/frontend-new/src/app/(dashboard)/datasets/[datasetId]/page.tsx`

### Modified Files
- `/apps/frontend-new/src/lib/api/endpoints.ts` - Added biasV2 endpoints
- `/apps/frontend-new/src/app/(dashboard)/datasets/page.tsx` - Added navigation

---

## ğŸ§ª Testing

### Manual Testing Checklist
- [ ] Upload a dataset via `/dashboard/datasets`
- [ ] Run a bias test using the dataset
- [ ] View test in history at `/dashboard/tests`
- [ ] Click test to see detailed results
- [ ] Check all metrics display correctly
- [ ] Verify recommendations appear
- [ ] Export test results as JSON
- [ ] Navigate to dataset detail page
- [ ] Verify schema and preview display
- [ ] Delete a dataset (with confirmation)

### API Testing
```bash
# Test history endpoint
curl http://localhost:8000/api/v1/bias-v2/history

# Test statistics endpoint
curl http://localhost:8000/api/v1/bias-v2/statistics

# Test detail endpoint
curl http://localhost:8000/api/v1/bias-v2/test/ml-test-20251123010000
```

---

## ğŸ¨ Screenshots

### Test History Page
- Filterable table with search
- Risk level badges
- Quick statistics cards
- Responsive design

### Test Detail Page
- Comprehensive metrics breakdown
- Visual progress indicators
- Group score comparisons
- Actionable recommendations

### Dataset Detail Page
- Schema visualization
- Data preview table
- Metadata display
- Quick action buttons

---

## ğŸ”’ Security Considerations

- âœ… **Row Level Security (RLS)**: Users can only see their own tests/datasets
- âœ… **JWT Authentication**: All API calls require valid token
- âœ… **Permission checks**: `require_permission()` decorators on endpoints
- âœ… **Input validation**: Pydantic models validate all inputs
- âœ… **Confirmation dialogs**: Destructive actions require confirmation

---

## ğŸ“š Documentation

### For Users
- Navigate to `/dashboard/tests` to view all bias tests
- Click any test to see detailed metrics and recommendations
- Use filters to find specific tests
- Export results for reporting

### For Developers
- All API endpoints are in `endpoints.ts`
- Custom hooks are in `lib/api/hooks/`
- Page components are in `app/(dashboard)/`
- Backend integration is via `api-client.ts`

---

## âœ¨ Summary

We've successfully built:
1. âœ… **Test History UI** - Complete with filtering and search
2. âœ… **Test Detail View** - Comprehensive metrics visualization
3. âœ… **Dataset Management** - Upload, view, delete datasets
4. âœ… **Dataset Detail View** - Schema, preview, metadata
5. âœ… **API Integration** - Full backend connectivity
6. âœ… **Type Safety** - TypeScript interfaces for all data
7. âœ… **Error Handling** - Proper loading states and error messages
8. âœ… **Responsive Design** - Works on all screen sizes

**The foundation is now ready for MLOps integrations like W&B, MLflow, or DVC!** ğŸš€
